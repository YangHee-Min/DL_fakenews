{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Q_uE7Y2D-5dh",
        "7WqRLj3P-tGs",
        "hxVTCoyV-npl"
      ],
      "authorship_tag": "ABX9TyO6bP2hm6ZNrCZaJmqgenGQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YangHee-Min/DL_fakenews/blob/main/Fakenews_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get imports"
      ],
      "metadata": {
        "id": "Q_uE7Y2D-5dh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A dependency of the preprocessing for BERT inputs\n",
        "!pip install -q -U \"tensorflow-text==2.8.*\""
      ],
      "metadata": {
        "id": "qj18AAJxU3pM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tf-models-official==2.7.0"
      ],
      "metadata": {
        "id": "QBG8PmtGQnI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization  # to create AdamW optimizer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "metadata": {
        "id": "0dT5ycOiQsg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download dataset from Google Drive"
      ],
      "metadata": {
        "id": "7WqRLj3P-tGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade --no-cache-dir gdown\n",
        "!gdown --id 1rkaWs5jNHswVGPsmoNjbGVXdkceuiUSp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERPopiBF-RiY",
        "outputId": "4fcfe292-0068-4e97-e3a0-5b4b6176e621"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:125: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1rkaWs5jNHswVGPsmoNjbGVXdkceuiUSp\n",
            "To: /content/News _dataset.zip\n",
            "100% 43.1M/43.1M [00:00<00:00, 71.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unzip file"
      ],
      "metadata": {
        "id": "hxVTCoyV-npl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "path_to_zip_file = '/content/News _dataset.zip'\n",
        "directory_to_extract_to = 'dataset'\n",
        "with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to)"
      ],
      "metadata": {
        "id": "bm6kxl80WAsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Datasets from CSV files"
      ],
      "metadata": {
        "id": "_XXctuMr_uki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get imports\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "dXlBwiOQAGvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def read_data(csv_path, is_true):\n",
        "  def add(title, text):\n",
        "    return title + \"\\n\" + text\n",
        "\n",
        "  data = pd.read_csv(csv_path)\n",
        "  data = data.drop('subject', axis=1).drop('date', axis=1)\n",
        "  data['title_text'] = data.apply(lambda row: add(row['title'], row['text']), axis=1)\n",
        "  data = data.drop('title', axis=1).drop('text', axis=1)\n",
        "\n",
        "  output_true = 0\n",
        "  if is_true:\n",
        "    output_true = 1\n",
        "  \n",
        "  data['is_true'] = output_true\n",
        "  return data\n",
        "\n",
        "# Fake data\n",
        "fake_path = \"./dataset/Fake.csv\"\n",
        "fake_data = read_data(fake_path, is_true=False)\n",
        "# fake_data.head()\n",
        "\n",
        "# True data\n",
        "true_path = \"./dataset/True.csv\"\n",
        "true_data = read_data(true_path, is_true=True)"
      ],
      "metadata": {
        "id": "kbBd1rrS_1zF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split each dataset into either train, validation or test"
      ],
      "metadata": {
        "id": "hsCWvQL9LJZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Vp4H8X1gLYDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the corresponding datasets\n",
        "t_train, t_test = train_test_split(true_data,test_size=0.2)\n",
        "t_train, t_validation = train_test_split(t_train, test_size=0.2)\n",
        "\n",
        "f_train, f_test = train_test_split(fake_data,test_size=0.2)\n",
        "f_train, f_validation = train_test_split(f_train, test_size=0.2)"
      ],
      "metadata": {
        "id": "CIo7ZYuYLxlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = pd.concat([t_train, f_train])\n",
        "validation_set = pd.concat([t_validation, f_validation])\n",
        "test_set = pd.concat([t_test, f_test])"
      ],
      "metadata": {
        "id": "lgM8dYajMySL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convert to tensorflow datasets"
      ],
      "metadata": {
        "id": "QA5edqDjUrlF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Convert to tf.DS from pd.Dataframe"
      ],
      "metadata": {
        "id": "gKYtuGdaWXNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices(dict(train_set))\n",
        "val_ds = tf.data.Dataset.from_tensor_slices(dict(validation_set))\n",
        "test_ds = tf.data.Dataset.from_tensor_slices(dict(test_set))"
      ],
      "metadata": {
        "id": "WbEHVWvSUInE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Transform Slices DS to Prefetch DS"
      ],
      "metadata": {
        "id": "UPgwB_9-WFiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "batch_size = 32\n",
        "seed = 42\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "Et9HeqQdVsxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for text_batch, label_batch in train_ds.take(1):\n",
        "  for i in range(3):\n",
        "    print(f'Review: {text_batch.numpy()[i]}')\n",
        "    label = label_batch.numpy()[i]\n",
        "    print(f'Label : {label}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66UajvDEW3gl",
        "outputId": "188bcef6-9b81-409e-ad05-3d2007f00a75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "title_text\n",
            "is_true\n"
          ]
        }
      ]
    }
  ]
}